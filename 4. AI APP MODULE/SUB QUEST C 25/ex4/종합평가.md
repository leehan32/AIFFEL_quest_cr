LMS와 Colab의 제약으로 인해 50회와 100회까지 학습을 진행한 후 결과를 분석하였으며,
이 과정에서 Loss를 지표로 활용하여 학습 진행 상황을 모니터링하는 것이 학습이 제대로 이루어지는지 직관적으로 확인하는 데 도움이 된다는 점을 경험했습니다.

또한, 두 번의 학습에서 생성된 이미지가 서로 다르게 나타나는 것을 관찰하였는데,
이러한 차이가 발생하는 이유로는

랜덤 초기화
랜덤 노이즈 입력
옵티마이저의 확률적 특성
등이 영향을 미칠 수 있음을 확인하였습니다.
이를 해결하기 위해 시드(seed) 값을 고정하면 동일한 조건에서 학습을 진행할 수 있지만,
딥러닝 프레임워크의 일부 연산이 비결정적(non-deterministic)일 수 있어 완전히 동일한 결과를 보장하기는 어렵다는 점도 알게 되었습니다.
또한, 노이즈 벡터를 고정하면 생성된 이미지의 기준점을 맞추는 데 도움이 될 수 있습니다.

한편, 같은 코드를 사용하여 200회까지 학습한 팀원의 결과를 분석한 결과,
80~90% 수준의 정밀도를 보이며 학습이 안정적으로 진행되고 있음을 확인할 수 있었습니다.
이를 통해 과적합(overfitting) 여부도 고려해 볼 필요가 있었습니다.

GAN에서 과적합이 발생하는 대표적인 경우는 다음과 같습니다.

데이터셋 크기가 너무 작은 경우
특정 클래스에 편향되어 특정 패턴만 생성하는 "모드 붕괴(Mode Collapse)" 현상
하지만, 이번 실험에서 생성된 이미지들이 서로 다르게 나타났으며, CIFAR 데이터셋이 약 6만 장으로 충분히 크고 클래스도 균형 있게 분포하고 있었기 때문에,
과적합보다는 정상적인 학습이 이루어지고 있다고 판단할 수 있었습니다.