# 인물 모드 사진 세그멘테이션 개선 전략

## 1. 목표

<aside>
💡

현재 인물 모드 사진을 생성할 때 발생하는 **경계 인식 오류 및 배경 블러 처리 오류**를 해결하고, 더욱 정교한 인물 모드 효과를 제공하는 솔루션을 구축한다.

</aside>

### 평가 기준

1. **인물 모드 사진을 성공적으로 제작**
    - 아웃포커싱(Blur) 처리된 인물 사진과 배경 전환(크로마키) 사진을 생성
2. **문제점을 정확히 지적**
    - 기존 모델이 인식하는 오류 분석
3. **솔루션 제시**
    - Semantic Segmentation Mask의 오류를 보완하는 최적의 방법론 도출

---

## 2. 문제점 분석

현재 DeepLabV3와 SAM을 조합하여 인물 모드를 생성하려 하지만, 다음과 같은 문제가 발생한다.

1. **DeepLabV3의 객체 검출 한계**
    - DeepLabV3가 배경과 사람을 정확히 구분하지 못하는 경우 발생
    - 사람 근처의 사물(예: 의자, 가방)이 사람과 함께 포함되는 오류 발생
2. **SAM의 클래스 정보 부족**
    - SAM은 세그멘테이션을 수행하지만, 클래스 정보가 없어 인물 사진 모드를 만들기 힘듦

---

## 3. 해결 방안 순서도

```
1. 더 정교한 객체 분리 (Object Segmentation 개선)
   → DeepLabV3 대신 SegFormer와 ConvNeXt를 결합하여 사람 객체 검출 성능 향상

2. 더 자연스러운 Blur 처리 (Depth & Edge-aware Blur)
   → Guided Filtering 및 Adaptive Gaussian Blur을 적용하여 경계 부드럽게 조정
```

---

## 4. 해결 방법론

### SegFormer + SAM + RefineNet 앙상블 모델 제안

### **1. 객체 분리 개선 (Object Segmentation 개선)**

**SegFormer + ConvNeXt 적용**

- 기존 DeepLabV3 대신 **SegFormer(Swin Transformer 기반) + ConvNeXt** 조합
- SegFormer: 넓은 문맥을 이해하면서 작은 객체도 인식 가능
- ConvNeXt: CNN 기반으로 빠르고 정확한 특징 추출 가능

장점: 사람과 배경을 정확히 분리하고, 작은 사물까지 정교하게 검출 가능

> 출처 :
https://arxiv.org/abs/2105.15203?utm_source=chatgpt.com
https://github.com/NVlabs/SegFormer
https://www.youtube.com/watch?v=t79E4gq4L-A&t=15s
https://arxiv.org/abs/2201.03545?utm_source=chatgpt.com
https://github.com/facebookresearch/ConvNeXt
> 

---

### **2. 경계 보정**

**RefineNet을 활용한 세부 경계 조정**

- **Conditional Random Field(CRF)** 기반 경계 보정 적용
- SAM이 잘못 분할한 영역을 **RefineNet이 보정하여 자연스러운 분할 수행**

> 출처 : 
https://pubmed.ncbi.nlm.nih.gov/38495379/
> 

---

### **3. Blur 처리 개선**

**Guided Filtering 기반 Blur**

- Blur 적용 전에 **Guided Filtering을 활용하여 경계를 유지**
    - Guided Image Filtering은 기존 필터들의 단점을 해결한 새로운 이미지 필터링 기법.
    - **엣지를 유지하면서도 부드럽게 노이즈를 제거할 수 있는 성질**을 가지며, 연산 속도가 빠르고 정확도가 높다.
    - 기존 Bilateral Filter와 달리 **Gradient Reversal(엣지 반전 현상)이 발생하지 않으며**, 다양한 영상 처리 및 컴퓨터 그래픽 응용에 효과적으로 사용할 수 있다.
    - 대표적으로 **노이즈 제거, 디테일 강조, HDR 압축, 이미지 매팅, 헤이즈 제거, 업샘플링** 등에 활용된다.
- Adaptive Gaussian Blur 적용하여 깊이 정보(Depth) 기반으로 배경을 부드럽게 흐림

 장점: 머리카락, 실루엣이 부드럽게 처리되면서 배경과 분리됨

> 출처 : 
https://journals.mmupress.com/index.php/jiwe/article/view/781?utm_source=chatgpt.com
https://people.csail.mit.edu/kaiming/publications/eccv10guidedfilter.pdf?utm_source=chatgpt.com
> 

---

## 5. 성능 평가 및 시각화

### **1. 성능 평가 기준**

| 평가 지표 | 설명 |
| --- | --- |
| **IoU (Intersection over Union)** | 사람이 포함된 영역이 정확히 검출되었는지 확인 |
| **mIoU (Mean IoU)** | 여러 클래스에서 평균 IoU 비교 |
| **Boundary F1-score** | 경계를 정확하게 구별했는지 평가 |
| **Pixel Accuracy** | 전체 픽셀 중 정확히 분류된 픽셀 비율 |

mIoU 계산 예시

| 클래스 | 실제 정답 크기 | 모델이 예측한 크기 | 겹친 부분 (IoU) |
| --- | --- | --- | --- |
| **사람** | 100 픽셀 | 90 픽셀 | **0.85** (85%) |
| **의자** | 50 픽셀 | 40 픽셀 | **0.75** (75%) |
| **배경** | 200 픽셀 | 180 픽셀 | **0.90** (90%) |

mIoU = (0.85 + 0.75 + 0.90) / 3 = 0.83

> 출처 :
https://modulabs.co.kr/blog/iou-intersection-over-union-%EA%B0%9D%EC%B2%B4-%ED%83%90%EC%A7%80-%ED%8F%89%EA%B0%80-%EC%A7%80%ED%91%9C
> 

### **2. 비교 실험 및 시각화**

**IoU 성능 비교 그래프**

```python
import matplotlib.pyplot as plt
import numpy as np

# IoU 값 설정
iou_baseline = [0.72, 0.68, 0.75]
iou_improved = [0.82, 0.78, 0.85]
categories = ["Person", "Dog", "Tree"]
x = np.arange(len(categories))

plt.figure(figsize=(8, 5))
plt.bar(x - 0.2, iou_baseline, 0.4, label="Baseline", color="gray")
plt.bar(x + 0.2, iou_improved, 0.4, label="Improved", color="blue")
plt.xticks(x, categories)
plt.xlabel("Categories")
plt.ylabel("IoU Score")
plt.title("IoU Comparison")
plt.legend()
plt.show()
```

**오버레이 비교 (Before vs After)**

```python
import cv2
import matplotlib.pyplot as plt

# 원본, 기존 세그멘테이션, 개선된 세그멘테이션 이미지 로드
original = cv2.imread("original.jpg")
baseline = cv2.imread("baseline.jpg", 0)
improved = cv2.imread("improved.jpg", 0)

fig, axes = plt.subplots(1, 3, figsize=(15, 5))
axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))
axes[0].set_title("Original")
axes[1].imshow(baseline, cmap="gray")
axes[1].set_title("Baseline")
axes[2].imshow(improved, cmap="gray")
axes[2].set_title("Improved")

for ax in axes:
    ax.axis("off")
plt.show()
```

---

## 6. 최종 결론

- 기존 DeepLabV3 + SAM의 한계를 극복하기 위해 **SegFormer + SAM + RefineNet 앙상블 모델**을 제안
- 경계를 더 부드럽고 자연스럽게 처리하는 후처리 기법 적용
- **Guided Filtering** 및 **Adaptive Gaussian Blur**를 적용하여 배경을 더 자연스럽게 흐리게 처리