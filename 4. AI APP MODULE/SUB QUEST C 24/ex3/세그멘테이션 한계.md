
세그멘테이션 
듀얼 카메라는 두개의 렌즈로 아웃 포커싱을 구현 하고 
DSLR에서는 사진 촬영할 때 피사게 심도 즉 초점맞은 피사체를 제외한 배경을 흐리게 만든다
핸드폰의 경우 일반(광각)렌즈에서 배경을 촬영하고 마원렌즈에서는 인물을 촬영후 합성
이번에는 세그멘 테이션을 이용하여 이걸 활용하고 셸로우포커스라고도 부릅니다.


이번에 사용할 모델은 DeepLABv3+이며 이 모델은 세그멘테이션을 위한 모델로 성능이 높은편

5장에서 했던것들에 문제점

##사람뒤의 옷이 블러처리가 제대로 안되거나 이런부분 문제의 이미지를 노트북에 포합해서 제출하기기

#코랩에서 구동시 파이썬 설치 폴더를 이용하여 변경할경우 이용 가능함함

#해결방안 제안해보기 <-어떻게?
단순히 'XXX 기술을 사용한다.' 정도의 선언적 솔루션이 아니라, 여러분들이 선택한 기술이 
DeepLab 모델의 Semantic Segmentation 이 만들어 낸 Mask 영역에 
어떻게 적용되어 문제점을 보완하게 되는지의 메커니즘이 포함된 솔루션이어야 합니다.

세그멘테이션의 한계
Semantic segmentation의 부정확성이 여러 가지 문제를 발생시키는 주요 원인
실제 피사계 심도를 이용한 아웃포커싱은 말 그대로 심도를 표현하기에 초점이 잡힌 거리르 광학적으로 섬세하기 구별하지만
이를 따라한 semantic segmentation은 픽셀 단위로 분할하기 때문에 실제 피사계 심도를 표현하기 어렵다. 
즉1.00이아닌이상 피사계 심도를 정확히 표현하기 어렵다.

피사계 심도 이해하기
심도는 보통 깊다(Large Depth of Field)와 얕다(Narrow Depth of Field)로 나뉜다.
아웃포커싱이 된 사진은 심도가 얕다고 하고 풍경사진 처럼 전체에 맞춘 사진은 심도가 깊다라고 한다.
아웃포커싱에 영향을 주는 요인
1.카메라의 이미지 센서가 클 수록
2.망원 렌즈를 쓰거나 줌을 했을 때
3.조리개가 많이 개방될 수록 (F값이 작을 수록)
4.카메라와 피사체간의 거리가 가까울 때
5.피사체와 배경의 거리가 멀 수록

3D 카메라 활용하기
3D 이미지센서는 기존 2D 이미지 센서와 달리 깊이 정보까지 측정할 수 있는 센서로서 더정밀하게
물체나 동작을 인식해 이를 3D로 표현할 수 있습니다. 이를 활용하면 세그멘테이션의 한계를 극복할 수 있습니다.
양안시각:두개의 이미지센서를 사용 사물까지의 거리 측정하고 이미지 구현 소형화가 어려움
구조광: 특정한 패턴의 빛을 물체에 조사한 뒤 입체적인 물체로 부터 반사돼 이미지센서로 돌아온 빛의 패턴이
왜곡된 정도를 소포트웨어를 통해 분석해 이미지를 획득하는 방식. 실외같이 빛이 강하면 어렵고 소포트웨어 부담이 높음
I-ToF 방식은 특정 주파수로 변조된 레이저를 이용해 물체로부터 반사돼 되돌아온 신호와의 위상 차이를 측정함으로써 물체까지의 거리를 측정하는 방식이다.
광검출 소자의 낮은 효율로 인해 수 미터 이상 떨어진 물체와 거리를 측정하기 어렵다
D-ToF 방식은 펄스 레이저를 사물에 조사해 반사된 펄스 신호들이 이미지센서에 도착하는 시간을 측정함으로써 물체까지의 거리를 탐지하는 방식이다.
펄스 레이저의 파워가 높아야 하고 레이저가 반사되어 돌아오는 시간을 정확하게 측정해야 하기 때문에 소포트웨어의 난이도가 높다. 
즉 초고효율을 제공하는 단광자눈사태다이오드가 필요하다.

소포트웨어 기술 활용하기
Struct2Depth는 단일 이미지로부터 깊이 정보를 추정하는 방식으로, 이미지의 픽셀 단위로 깊이 정보를 추정한다.
이는 원래의 레이다 센서를 활용하거나 두개의 카메라를 활용과 방법과 달리 비디오만으로도 학습이 가능하다.

다른 기술과 융합해보기
픽셀4핸드폰에서 적외선 센서를 적용하여 야간에도 뚜렷하게 얼굴잠금해제 기능이 활용가능함 즉 깊이에 대한 정보를 추가로 인식가능
