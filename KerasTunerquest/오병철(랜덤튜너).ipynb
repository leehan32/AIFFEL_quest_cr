{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2REdWegUaYGe",
        "outputId": "647625a5-a2c2-48cb-866c-d894cea97ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 01m 02s]\n",
            "val_accuracy: 0.7305999994277954\n",
            "\n",
            "Best val_accuracy So Far: 0.7305999994277954\n",
            "Total elapsed time: 00h 04m 16s\n",
            "\n",
            "최적의 하이퍼파라미터:\n",
            "Conv2D 필터 수: 128\n",
            "Conv2D kernel size: 3\n",
            "Dropout rate: 0.1\n",
            "Dense 유닛 수: 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7184 - loss: 0.9840\n",
            "\n",
            "테스트 세트 성능:\n",
            "Loss: 0.9963\n",
            "Accuracy: 0.7142\n"
          ]
        }
      ],
      "source": [
        "# Colab에서 keras-tuner 설치\n",
        "!pip install keras-tuner\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras_tuner import RandomSearch\n",
        "import numpy as np\n",
        "\n",
        "# 하이퍼파라미터 튜닝을 위한 모델 빌더 함수\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 1. Conv2D 필터 수 튜닝 (32-128)\n",
        "    filters = hp.Int('conv_1_filters', min_value=32, max_value=128, step=32)\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=filters,\n",
        "        kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),  # 2. kernel size 튜닝\n",
        "        activation='relu',\n",
        "        input_shape=(32, 32, 3)\n",
        "    ))\n",
        "\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # 3. Dropout rate 튜닝 (0.1-0.5)\n",
        "    dropout_rate = hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(layers.Conv2D(64, 3, activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # 4. Dense 레이어의 유닛 수 튜닝 (64-256)\n",
        "    dense_units = hp.Int('dense_units', min_value=64, max_value=256, step=64)\n",
        "    model.add(layers.Dense(dense_units, activation='relu'))\n",
        "\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # 컴파일\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# GPU 확인\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# 검증 세트 분리\n",
        "val_size = 5000\n",
        "x_val = x_train[-val_size:]\n",
        "y_val = y_train[-val_size:]\n",
        "x_train = x_train[:-val_size]\n",
        "y_train = y_train[:-val_size]\n",
        "\n",
        "# 하이퍼파라미터 튜닝 실행\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,  # 시도 횟수\n",
        "    directory='cifar10_tuning',\n",
        "    project_name='cifar10_cnn'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_val, y_val),\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"\\n최적의 하이퍼파라미터:\")\n",
        "print(f\"Conv2D 필터 수: {best_hps.get('conv_1_filters')}\")\n",
        "print(f\"Conv2D kernel size: {best_hps.get('conv_1_kernel')}\")\n",
        "print(f\"Dropout rate: {best_hps.get('dropout_1')}\")\n",
        "print(f\"Dense 유닛 수: {best_hps.get('dense_units')}\")\n",
        "\n",
        "# 최적의 모델로 최종 평가\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "evaluation = best_model.evaluate(x_test, y_test)\n",
        "print(f\"\\n테스트 세트 성능:\")\n",
        "print(f\"Loss: {evaluation[0]:.4f}\")\n",
        "print(f\"Accuracy: {evaluation[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "최적화 결과\n",
        "\t•\t검증 정확도(val_accuracy)가 약 73.06%로 나왔으며, 이는 지금까지의 시도 중 가장 좋은 결과입니다.\n",
        "\t•\t총 소요 시간은 4분 16초입니다.\n",
        "최적의 하이퍼파라미터\n",
        "모델이 가장 좋은 성능을 보인 설정은:\n",
        "\t•\tConv2D 레이어의 필터 수: 128개\n",
        "\t•\t컨볼루션 커널 크기: 3x3\n",
        "\t•\t드롭아웃 비율: 0.1 (즉, 뉴런의 10%를 무작위로 비활성화)\n",
        "\t•\tDense 레이어의 유닛 수: 128개\n",
        "최종 테스트 결과\n",
        "\t•\t손실(Loss): 0.9963\n",
        "\t•\t정확도(Accuracy): 71.42%\n",
        "이는 모델이 테스트 데이터에 대해 약 71%의 정확도를 보여주며, 실제 현장에서 적용했을 때 10개 중 7개 정도를 올바르게 예측할 수 있다는 의미입니다. 검증 정확도(73.06%)와 테스트 정확도(71.42%)가 비슷한 수준을 보이는 것으로 보아, 모델이 적절하게 일반화되었다고 볼 수 있습니다"
      ],
      "metadata": {
        "id": "vKipSsyYiqLf"
      }
    }
  ]
}