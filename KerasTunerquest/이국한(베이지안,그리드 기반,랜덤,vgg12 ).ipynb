{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ë¯¸ì…˜\n",
        "\n",
        "<aside>\n",
        "ğŸ“Œ\n",
        "\n",
        "4ê°€ì§€ ì´ìƒì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ìµœì ì˜ ëª¨ë¸ì„ ì°¾ì•„ë´…ì‹œë‹¤.\n",
        "\n",
        "- ìµœì ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ì¹˜\n",
        "- í•´ë‹¹ ëª¨ë¸ í‰ê°€ ê²°ê³¼ : val_accuracy, val_loss\n",
        "</aside>\n",
        "\n",
        "### í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "\n",
        "- Unit size\n",
        "- Kernel size\n",
        "- Dropout rate\n",
        "- Optimizer\n",
        "- Learning rate\n",
        "- Activation functions\n",
        "- Batch size\n",
        "- Regularization\n",
        "- Strides\n",
        "- Padding\n",
        "- Conv, í’€ë§ Layer ê°¯ìˆ˜\n",
        "- â€¦ë“±"
      ],
      "metadata": {
        "id": "CxoR_wjhXWX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UavDz2qRXsqJ",
        "outputId": "52ea85c8-1d44-44ca-c5ef-ef7186b3e589"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EHxz3pv9XNvl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7pe_vX_XPiV",
        "outputId": "d54dc1bd-8f3c-41ec-b6d6-b4e01975e8fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "06HOWWQeZuM2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=(32, 32, 3)))\n",
        "\n",
        "    # Conv2D ë ˆì´ì–´ ì¶”ê°€\n",
        "    for i in range(hp.Int(\"conv_layers\", 2, 4)):  # 2~4ê°œì˜ Conv ë ˆì´ì–´\n",
        "        model.add(\n",
        "            layers.Conv2D(\n",
        "                filters=hp.Choice(f\"filters_{i}\", [32, 64, 128, 256]),\n",
        "                kernel_size=hp.Choice(\"kernel_size\", [3, 5]),\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        # MaxPooling2Dì— padding=\"same\" ì¶”ê°€ ë° í¬ê¸° í™•ì¸\n",
        "        if model.layers[-1].output_shape[1] >= 2 and model.layers[-1].output_shape[2] >= 2:\n",
        "            model.add(layers.MaxPooling2D(pool_size=2, padding=\"same\"))\n",
        "        else:\n",
        "            print(\"ì…ë ¥ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ì•„ MaxPooling2Dë¥¼ ìƒëµí•©ë‹ˆë‹¤.\")\n",
        "            break\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense ë ˆì´ì–´ ì¶”ê°€\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "            units=hp.Int(\"dense_units\", min_value=64, max_value=512, step=64),\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "    )\n",
        "    model.add(layers.Dropout(rate=hp.Float(\"dropout_rate\", 0.2, 0.5, step=0.1)))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    # ì»´íŒŒì¼ ì„¤ì •\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4, 1e-5])\n",
        "        ),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ë² ì´ì§€ì•ˆ ìµœì í™” ì„¤ì •\n",
        "tuner = kt.BayesianOptimization(\n",
        "    hypermodel=build_model,  # í•˜ì´í¼ëª¨ë¸ í•¨ìˆ˜\n",
        "    objective=\"val_accuracy\",  # ìµœì í™” ëª©í‘œ\n",
        "    max_trials=15,  # ìµœëŒ€ ì‹œë„ íšŸìˆ˜\n",
        "    num_initial_points=3,  # ì´ˆê¸° ëœë¤ ì‹œë„ ìˆ˜\n",
        "    alpha=0.0001,  # íƒìƒ‰ ê³µê°„ì˜ ê· í˜•ì„ ì¡°ì ˆ\n",
        "    beta=2.6,  # íƒìƒ‰ ê°•ë„ë¥¼ ì¡°ì ˆ\n",
        "    seed=42,  # ëœë¤ ì‹œë“œ\n",
        "    directory=\"bayesian_tuning_cifar10\",  # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬\n",
        "    project_name=\"cifar10_bayesian\",  # í”„ë¡œì íŠ¸ ì´ë¦„\n",
        ")\n",
        "\n",
        "# íŠœë‹ ì‹œì‘\n",
        "tuner.search(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=5,  # í•œ ë²ˆì˜ ì‹œë„ì—ì„œ í•™ìŠµí•  ìµœëŒ€ ì—í¬í¬\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=3)],  # ì¡°ê¸° ì¢…ë£Œ ì½œë°±\n",
        ")\n",
        "\n",
        "# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
        "for param, value in best_hps.values.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# ìµœì  ëª¨ë¸ ì¬í•™ìŠµ\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=20,  # ìµœì  ëª¨ë¸ ì¬í•™ìŠµ\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=3)],  # ì¡°ê¸° ì¢…ë£Œ ì½œë°±\n",
        ")\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc}\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mZRoRrcYZvIa",
        "outputId": "89ffef10-57da-4f90-8ba8-9b6d9ecdd45e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from bayesian_tuning_cifar10/cifar10_bayesian/tuner0.json\n",
            "\n",
            "Search: Running Trial #15\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "3                 |2                 |conv_layers\n",
            "128               |128               |filters_0\n",
            "5                 |3                 |kernel_size\n",
            "64                |64                |filters_1\n",
            "128               |256               |dense_units\n",
            "0.4               |0.4               |dropout_rate\n",
            "0.01              |0.001             |learning_rate\n",
            "32                |64                |filters_2\n",
            "32                |None              |filters_3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
            "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
            "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 232, in _build_and_fit_model\n",
            "    model = self._try_build(hp)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 164, in _try_build\n",
            "    model = self._build_hypermodel(hp)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 155, in _build_hypermodel\n",
            "    model = self.hypermodel.build(hp)\n",
            "  File \"<ipython-input-19-496e35249a21>\", line 15, in build_model\n",
            "    if model.layers[-1].output_shape[1] >= 2 and model.layers[-1].output_shape[2] >= 2:\n",
            "AttributeError: 'Conv2D' object has no attribute 'output_shape'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 232, in _build_and_fit_model\n    model = self._try_build(hp)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 164, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 155, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"<ipython-input-19-496e35249a21>\", line 15, in build_model\n    if model.layers[-1].output_shape[1] >= 2 and model.layers[-1].output_shape[2] >= 2:\nAttributeError: 'Conv2D' object has no attribute 'output_shape'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-496e35249a21>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# íŠœë‹ ì‹œì‘\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m tuner.search(\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mLOCKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthread_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_acquire\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_consecutive_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36m_check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    546\u001b[0m                     \u001b[0;34m\"Number of consecutive failures exceeded the limit \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                     \u001b[0;34mf\"of {self.max_consecutive_failed_trials}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 232, in _build_and_fit_model\n    model = self._try_build(hp)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 164, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 155, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"<ipython-input-19-496e35249a21>\", line 15, in build_model\n    if model.layers[-1].output_shape[1] >= 2 and model.layers[-1].output_shape[2] >= 2:\nAttributeError: 'Conv2D' object has no attribute 'output_shape'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•˜ì´í¼ëª¨ë¸ ì •ì˜\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=(32, 32, 3)))\n",
        "\n",
        "    # Conv2D ë ˆì´ì–´ ì¶”ê°€\n",
        "    for i in range(hp.Int(\"conv_layers\", 2, 4)):  # 2~4ê°œì˜ Conv ë ˆì´ì–´\n",
        "        model.add(\n",
        "            layers.Conv2D(\n",
        "                filters=hp.Choice(f\"filters_{i}\", [32, 64, 128, 256]),\n",
        "                kernel_size=hp.Choice(\"kernel_size\", [3, 5]),\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        model.add(layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense ë ˆì´ì–´ ì¶”ê°€\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "            units=hp.Int(\"dense_units\", min_value=64, max_value=512, step=64),\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "    )\n",
        "    model.add(layers.Dropout(rate=hp.Float(\"dropout_rate\", 0.2, 0.5, step=0.1)))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    # ì»´íŒŒì¼ ì„¤ì •\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4, 1e-5])\n",
        "        ),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ê·¸ë¦¬ë“œ ê²€ìƒ‰ ê¸°ë°˜ ìµœì í™” (Hyperband)\n",
        "tuner = kt.Hyperband(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=10,  # ìµœëŒ€ ì—í¬í¬ ìˆ˜\n",
        "    factor=3,       # ìì› ë¶„ë°° ë¹„ìœ¨\n",
        "    seed=42,\n",
        "    directory=\"hyperband_tuning_cifar10\",\n",
        "    project_name=\"cifar10_hyperband\",\n",
        ")\n",
        "\n",
        "# íŠœë‹ ì‹œì‘\n",
        "tuner.search(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=3)],\n",
        ")\n",
        "\n",
        "# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
        "for param, value in best_hps.values.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# ìµœì  ëª¨ë¸ ì¬í•™ìŠµ\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=3)],\n",
        ")\n",
        "\n",
        "# í‰ê°€\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc}\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcomco85alpI",
        "outputId": "56fd8dc4-fae4-4605-d795-8af3f43a44db"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 24 Complete [00h 01m 37s]\n",
            "val_accuracy: 0.6628999710083008\n",
            "\n",
            "Best val_accuracy So Far: 0.6934999823570251\n",
            "Total elapsed time: 00h 11m 34s\n",
            "ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\n",
            "conv_layers: 2\n",
            "filters_0: 128\n",
            "kernel_size: 3\n",
            "filters_1: 256\n",
            "dense_units: 448\n",
            "dropout_rate: 0.30000000000000004\n",
            "learning_rate: 0.001\n",
            "filters_2: 256\n",
            "filters_3: 64\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.4172 - loss: 1.5981 - val_accuracy: 0.6303 - val_loss: 1.0587\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6413 - loss: 1.0216 - val_accuracy: 0.6795 - val_loss: 0.9310\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7066 - loss: 0.8359 - val_accuracy: 0.7069 - val_loss: 0.8443\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7554 - loss: 0.6916 - val_accuracy: 0.7188 - val_loss: 0.8354\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7975 - loss: 0.5736 - val_accuracy: 0.7233 - val_loss: 0.8380\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8359 - loss: 0.4708 - val_accuracy: 0.7273 - val_loss: 0.8719\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.3842 - val_accuracy: 0.7192 - val_loss: 0.9102\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.8984\n",
            "í…ŒìŠ¤íŠ¸ ì •í™•ë„: 0.7192000150680542\n",
            "í…ŒìŠ¤íŠ¸ ì†ì‹¤: 0.9102368950843811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•˜ì´í¼ëª¨ë¸ ì •ì˜\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=(32, 32, 3)))\n",
        "\n",
        "    # Conv2D ë ˆì´ì–´ ì¶”ê°€\n",
        "    for i in range(hp.Int(\"conv_layers\", 2, 4)):  # 2~4ê°œì˜ Conv ë ˆì´ì–´\n",
        "        model.add(\n",
        "            layers.Conv2D(\n",
        "                filters=hp.Choice(f\"filters_{i}\", [32, 64, 128, 256]),\n",
        "                kernel_size=hp.Choice(\"kernel_size\", [3, 5]),\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        model.add(layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense ë ˆì´ì–´ ì¶”ê°€\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "            units=hp.Int(\"dense_units\", min_value=64, max_value=512, step=64),\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "    )\n",
        "    model.add(layers.Dropout(rate=hp.Float(\"dropout_rate\", 0.2, 0.5, step=0.1)))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    # ì»´íŒŒì¼ ì„¤ì •\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4, 1e-5])\n",
        "        ),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ëœë¤ ê²€ìƒ‰ (Random Search)\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=15,  # íƒìƒ‰ ì‹œë„ íšŸìˆ˜\n",
        "    seed=42,\n",
        "    directory=\"random_tuning_cifar10\",\n",
        "    project_name=\"cifar10_random\",\n",
        ")\n",
        "\n",
        "# íŠœë‹ ì‹œì‘\n",
        "tuner.search(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=3)],\n",
        ")\n",
        "\n",
        "# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
        "for param, value in best_hps.values.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# ìµœì  ëª¨ë¸ ì¬í•™ìŠµ\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=3)],\n",
        ")\n",
        "\n",
        "# í‰ê°€\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc}\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cksdXeaQazsP",
        "outputId": "da155897-5be6-4b4d-d38b-32da8f2d4cd1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15 Complete [00h 00m 03s]\n",
            "\n",
            "Best val_accuracy So Far: 0.7390999794006348\n",
            "Total elapsed time: 00h 14m 54s\n",
            "ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\n",
            "conv_layers: 2\n",
            "filters_0: 256\n",
            "kernel_size: 5\n",
            "filters_1: 256\n",
            "dense_units: 512\n",
            "dropout_rate: 0.2\n",
            "learning_rate: 0.0001\n",
            "filters_2: 64\n",
            "filters_3: 128\n",
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.3515 - loss: 1.7848 - val_accuracy: 0.5338 - val_loss: 1.3140\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5607 - loss: 1.2455 - val_accuracy: 0.6071 - val_loss: 1.1167\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6311 - loss: 1.0540 - val_accuracy: 0.6450 - val_loss: 0.9983\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6755 - loss: 0.9420 - val_accuracy: 0.6826 - val_loss: 0.9135\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7103 - loss: 0.8412 - val_accuracy: 0.6931 - val_loss: 0.8898\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7438 - loss: 0.7467 - val_accuracy: 0.7144 - val_loss: 0.8305\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7678 - loss: 0.6751 - val_accuracy: 0.7214 - val_loss: 0.8103\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7895 - loss: 0.6102 - val_accuracy: 0.7254 - val_loss: 0.8005\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8131 - loss: 0.5548 - val_accuracy: 0.7305 - val_loss: 0.8017\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8361 - loss: 0.4811 - val_accuracy: 0.7412 - val_loss: 0.7715\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 0.7647\n",
            "í…ŒìŠ¤íŠ¸ ì •í™•ë„: 0.7411999702453613\n",
            "í…ŒìŠ¤íŠ¸ ì†ì‹¤: 0.7714968323707581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg16_model(hp):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # VGG16ì˜ íŠ¹ì§•: Conv ë¸”ë¡ê³¼ MaxPooling\n",
        "    for i in range(3):  # VGG16ì˜ ê¸°ë³¸ ë¸”ë¡ 3ê°œ\n",
        "        model.add(\n",
        "            layers.Conv2D(\n",
        "                filters=hp.Choice(f\"filters_block_{i}\", [64, 128, 256]),\n",
        "                kernel_size=3,\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        model.add(\n",
        "            layers.Conv2D(\n",
        "                filters=hp.Choice(f\"filters_block_{i}\", [64, 128, 256]),\n",
        "                kernel_size=3,\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Fully Connected ë ˆì´ì–´\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "            units=hp.Int(\"dense_units\", min_value=256, max_value=512, step=128),\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "    )\n",
        "    model.add(layers.Dropout(rate=hp.Float(\"dropout_rate\", 0.2, 0.5, step=0.1)))\n",
        "\n",
        "    # ì¶œë ¥ ë ˆì´ì–´\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    # ì»´íŒŒì¼ ì„¤ì •\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            learning_rate=hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])\n",
        "        ),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# íŠœë„ˆ ì„¤ì • (ëœë¤ ê²€ìƒ‰ ë˜ëŠ” í•˜ì´í¼ë°´ë“œ ì¤‘ ì„ íƒ)\n",
        "tuner = kt.Hyperband(\n",
        "    hypermodel=build_vgg16_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=10,  # ìµœëŒ€ ì—í¬í¬ ìˆ˜\n",
        "    factor=3,       # ìì› ë¶„ë°° ë¹„ìœ¨\n",
        "    seed=42,\n",
        "    directory=\"vgg16_tuning\",\n",
        "    project_name=\"cifar10_vgg16\",\n",
        ")\n",
        "\n",
        "# íŠœë‹ ì‹œì‘\n",
        "tuner.search(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=3)],\n",
        ")\n",
        "\n",
        "# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
        "for param, value in best_hps.values.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# ìµœì  ëª¨ë¸ ì¬í•™ìŠµ\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=3)],\n",
        ")\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc}\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BEefgOannVR",
        "outputId": "0a40cbe4-8760-405b-c550-dc7a6296aeba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 26 Complete [00h 04m 56s]\n",
            "val_accuracy: 0.751800000667572\n",
            "\n",
            "Best val_accuracy So Far: 0.7681000232696533\n",
            "Total elapsed time: 00h 36m 32s\n",
            "\n",
            "Search: Running Trial #27\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "256               |128               |filters_block_0\n",
            "64                |64                |filters_block_1\n",
            "256               |128               |filters_block_2\n",
            "512               |384               |dense_units\n",
            "0.3               |0.2               |dropout_rate\n",
            "0.01              |0.001             |learning_rate\n",
            "10                |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "0                 |2                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.1016 - loss: 14.8041 - val_accuracy: 0.1000 - val_loss: 2.3047\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 21ms/step - accuracy: 0.1011 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.0988 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.1029 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.0966 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.1010 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3047\n",
            "Epoch 7/10\n",
            "\u001b[1m 737/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1030 - loss: 2.3044"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eo5BFkv5qY5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì˜¨10ê¸°/ì´êµ­í•œ/ì½”ì–´/ì„œìš¸\n",
        "ì´ë²ˆì— í€˜ìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ê²Œ ë˜ë©´ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™í™” ì¦‰ íŠœë„ˆ ê¸°ëŠ¥ì— ëŒ€í•´ ë‹¤ë¤„ ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ a-zê¹Œì§€ ì§ì ‘ ì½”ë“œë¥¼ ì…ë ¥í•˜ê¸°ë³´ë‹¤ëŠ” ì–´ëŠì •ë„ ì´ˆì•ˆì„ ë°›ì•„ íŠœë„ˆ ì¢…ë¥˜ë¥¼ ë°”ê¿”ì„œ ì‚¬ìš©í•´ë´¤ê³  ì‚¬ìš©í•¨ì— ë”°ë¼ ì–´ë–¤ ë¶€ë¶„ë“¤ì´ ìˆ˜ì •ë˜ì–´ ë°”ë€Œì–´ë‚˜ê°€ëŠ”ì§€ ë˜ ì´ë ‡ê²Œ íƒìƒ‰í•´ ë‚˜ê°€ëŠ” ê³¼ì •ì—ì„œ ì•ì—ì„œ ë‹¤ë£¨ì–´ ë´¤ë˜ ëª¨ë¸ë„ í•œë²ˆ ì ìš©í•´ ë³´ë©´ì„œ ì¢€ ë” í¸í•´ì§„ ë¶€ë¶„ë„ ìˆì§€ë§Œ ì‹¤ì§ˆì ìœ¼ë¡œ ì œëŒ€ë¡œ ì•Œê³  ì“°ì§€ ì•Šìœ¼ë©´ ë‹¨ìˆœíˆ ì‹œê°„ë§Œ ê¸¸ì–´ì§€ê³  ë¹„ìš©ë§Œ  ëŠ˜ì–´ë‚˜ê²Œë˜ëŠ” ë¶€ë¶„ë„ ë§ì´ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œê²Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "\n",
        "ì˜¨10ê¸°/ì˜¤ë³‘ì² /ì½”ì–´/ê²½ê¸°\n",
        "íšŒê³ : ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•˜ë©´ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì˜ ì¤‘ìš”ì„±ì„ ê¹¨ë‹¬ì•˜ê³ , íŠ¹íˆ í•™ìŠµë¥ ê³¼ ë°°ì¹˜ í¬ê¸°ê°€ ëª¨ë¸ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì ì´ ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤. ResNet êµ¬ì¡°ë¥¼ ë°°ìš°ë©´ì„œ Skip Connectionì´ë¼ëŠ” í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¡œ ê¹Šì€ ì‹ ê²½ë§ì˜ í•™ìŠµ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ í¥ë¯¸ë¡œì› ìŠµë‹ˆë‹¤. ì‹¤ì œ ëª¨ë¸ êµ¬í˜„ê³¼ íŠœë‹ ê³¼ì •ì—ì„œ 71%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆëŠ”ë°, ì´ë¡ ì  ì§€ì‹ì„ ì‹¤ì œ êµ¬í˜„ìœ¼ë¡œ ì˜®ê¸°ëŠ” ê³¼ì •ì—ì„œ ë§ì€ ì‹œí–‰ì°©ì˜¤ì™€ ë°°ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "8FZ78izLxDeG"
      }
    }
  ]
}